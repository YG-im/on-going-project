{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#root_meam_squared_error\n",
    "def rmse(predictions, targets):\n",
    "    return np.sqrt(((predictions - targets) ** 2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categ_or_contin(df, criterion=10, cat_or_cont=True, print_col = True):\n",
    "    '''\n",
    "    df의 column을 이루고 있는 value들 종류 갯수를 파악하여 연속형 변수와 범주형 변수로 구분해주는 함수.\n",
    "    cat_or_cont = True (default) : 연속형 변수 출력\n",
    "    cat_or_cont = False : 범주형 변수 출력\n",
    "    criterion(default = 10) : 연속과 범주형의 기준 제시.\n",
    "    ex) criterion = 10 : value의 종류가 10종이하이면 범주형 변수, 넘으면 연속형 변수\n",
    "    ex) categ_or_contin(house6[0],15,False)\n",
    "    '''   \n",
    "    target_skew = df\n",
    "    categorical = []\n",
    "    continuous = []\n",
    "\n",
    "    for column in target_skew: \n",
    "        if len(set(target_skew[column])) > criterion: # 범주형과 연속형 변수 구분 필요함. \n",
    "            continuous.append(column)  # 연속형\n",
    "        else:\n",
    "            categorical.append(column) #범주형\n",
    "    if print_col == True:\n",
    "        print('- categorical variables : ', categorical, '\\n- continuous variables : ', continuous)\n",
    "    return continuous if cat_or_cont==True else categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_for_transf(df, col_str, transf_ls):\n",
    "    '''\n",
    "    Continous variable의 적절한 전처리를 위하여 '입력된 수식들로 변환된 column' vs 'frequency'의 그래프를 출력하는 함수.\n",
    "    (사용시 추천예시) : 이렇게 같은 cell에 variable들을 정의하고, 함수안에선 수식만 바꾸면 더 편하다.\n",
    "    df = house7[0]; col_str = 'bathrooms'; x = df[col_str];\n",
    "    test_for_transf(df, col_str ,[x, np.log(x), (x-x.min())**(2/3)] )\n",
    "\n",
    "    df : 해당 데이터프레임 입력\n",
    "    col_str : df에서 확인해보고 싶은 column 하나를 string으로 입력 ex) 'price'\n",
    "    transf_ls : 'del x'를 선행한 후 테스트 해보고 싶은 transfromation 수식을 target에대한 함수로 만들어서 list형태로 입력 \n",
    "        ex) [(x-x.min())^2, np.log(x)]\n",
    "    '''\n",
    "    from scipy.stats import norm\n",
    "    target_col = col_str\n",
    "    target = df[target_col]\n",
    "    target_transf = transf_ls # test해보고 싶은 transf 수식들 다 list 안에 넣기\n",
    "    for i in range(len(target_transf)):\n",
    "        # let's plot a histogram with the fitted parameters used by the function\n",
    "        sns.distplot(target_transf[i] , fit=norm);\n",
    "        # get mean and standard deviation\n",
    "        (mu, sigma) = norm.fit(target_transf[i])\n",
    "        # add legends to the plot\n",
    "        plt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n",
    "                    loc='best')\n",
    "        plt.ylabel('Frequency')\n",
    "#        plt.title(target_col)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_skew(df, column_list_=None, skewness=1.5, criterion_of_cont_var=15, print_col_=True):\n",
    "    '''\n",
    "    df의 column인 column_list 중 왜도(skewness)가 1.5(default)보다 큰 column을 출력하는 함수.\n",
    "    column_list(default=df.column, True = 연속형, False = 범주형, list = 그 list) \n",
    "            : df의 column들 중 왜도를 확인해볼 column list 입력. \n",
    "    skewness(default=1.5) : 기준 왜도값 입력.\n",
    "    print_col_(default=True) : True이면 연속형 변수와 범주형 변수들을 리스트 형태로 보여줌\n",
    "    '''\n",
    "    from scipy.stats import skew\n",
    "    target_skew = df\n",
    "    if column_list_ == None: #구분할 행을 입력하지 않으면 df의 전체 행을 입력해준다.\n",
    "        column_list=list(df.columns)\n",
    "    elif column_list_ == True:\n",
    "        column_list=categ_or_contin(target_skew,criterion_of_cont_var,True, print_col=print_col_)\n",
    "    elif column_list_ == False:\n",
    "        column_list=categ_or_contin(target_skew,criterion_of_cont_var,False, print_col=print_col_)\n",
    "    else :\n",
    "        column_list=column_list_\n",
    "    # df.skew(): 열별 왜도\n",
    "    biased_condition = abs(target_skew[column_list].skew()) > skewness # biased_condition : 1.5보다 크면 치우쳤다고 간주함\n",
    "    # biased_variables: 왜도의 절대 값이 1.5보다 큰 변수\n",
    "    biased_variables = target_skew[column_list].columns[biased_condition] \n",
    "    print('Columns {}에서 \\n skewness가 {}보다 높은 columns은 {}이다.\\n'.format(column_list, skewness, list(biased_variables)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Remove_outliers(IQR_target_df, criterion_of_cont_var=15, criterion_Q1=0.25, criterion_Q3=0.75):\n",
    "    '''\n",
    "    IQR rule에 따라 연속형 변수의 이상치를 제거해주는 함수.\n",
    "    IQR rule : Q3-1.5*IQR보다 크거나 Q1-1.5*IQR보다 작으면 이상치라고 판단. 삭제\n",
    "    IQR_target_df : 타겟이 될 데이터 프레임\n",
    "    criterion_of_cont_var (default=15) : 연속형 변수의 기준.\n",
    "    ex) Remove_outliers(house4_1[0], 20)\n",
    "    '''\n",
    "    IQR_target = IQR_target_df #house4_1[0]\n",
    "    continuous_IQR = categ_or_contin(IQR_target,criterion_of_cont_var,print_col=False)\n",
    "\n",
    "    len_before = len(IQR_target)\n",
    "    Q1 = IQR_target[continuous_IQR].quantile(criterion_Q1)\n",
    "    Q3 = IQR_target[continuous_IQR].quantile(criterion_Q3)\n",
    "    IQR = Q3 - Q1\n",
    "    condition1 = Q1 - 1.5*IQR < IQR_target[continuous_IQR]\n",
    "    condition2 = Q3 + 1.5*IQR > IQR_target[continuous_IQR]\n",
    "    IQR_target[continuous_IQR] = IQR_target[continuous_IQR][condition1 & condition2]\n",
    "    # IQR rule : Q3-1.5*IQR보다 크거나 Q1-1.5*IQR보다 작으면 이상치라고 판단. 삭제\n",
    "    IQR_target.dropna(inplace=True)\n",
    "    IQR_target.reset_index(drop=True, inplace=True)\n",
    "    len_after = len(IQR_target)\n",
    "    print('Outliers are completely removed. Length is redeced from {} to {}'.format(len_before, len_after))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_category(target, criterion_of_cont_var=15, sort_category = False):\n",
    "    '''\n",
    "    target의 columns 중 categorical variable의 category 종류 및 각 category에 대한 샘플의 수를 count해주는 함수.\n",
    "    target : 원하는 dataframe을 입력.\n",
    "    criterion_of_cont_var (default=10) : categorical variable의 기준을 입력.\n",
    "        ex) criterion_of_cont_var=10 : variable이 10 종 이하로 전부 분류되면 categorical variable.\n",
    "    sort_category (default = False) : False면 sample수가 많은 카테고리 순으로 배열, True면 카테고리를 오름차순으로 배열\n",
    "    '''\n",
    "    count_target = target\n",
    "    result = []\n",
    "    categ_var = categ_or_contin(count_target,criterion_of_cont_var,False,False)\n",
    "    \n",
    "    for i in range(len(categ_var)):\n",
    "        pd_count = count_target[categ_var[i]].value_counts()\n",
    "        pd_count = pd_count.reset_index().rename(columns = {'index': 'category'})\n",
    "        if sort_category == True:\n",
    "            pd_count.sort_values(by = ['category'], ascending=sort_category, inplace=True)\n",
    "            pd_count.reset_index(drop=True, inplace=True)\n",
    "        result.append(pd_count)\n",
    "    return pd.concat(result,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_vs_frequency(df_target_, figsize_tuple_ = (12,10), loc_='best'):\n",
    "    '''\n",
    "    df_target_의 features_들의 분포를 행렬 그래프로 그리는 함수\n",
    "    df_target_ : 그래프들 그려볼 data frame\n",
    "    figsize_tuple_ : 전체 그래프 사이즈를 튜플로 입력\n",
    "    loc_ : lengend 위치 설정\n",
    "      ex) loc_ = 'best', 'upper right', 'upper left', 'lower left', 'lower right', 'right', \n",
    "                'center left', 'center right', 'lower center', 'upper center', 'center' \n",
    "    '''\n",
    "    from scipy.stats import norm\n",
    "    \n",
    "    df_target = df_target_\n",
    "    figsize_tuple = figsize_tuple_\n",
    "    \n",
    "    col = df_target.columns # df_target의 feature list\n",
    "    \n",
    "    # data frame의 feature의 갯수에 따라 적절한 행과 열을 결정해준다.\n",
    "    length = len(col)\n",
    "    row_len = int(round(length**(1/2),0))\n",
    "    col_len = int(round(length/row_len,0))+1 if row_len*round(length/row_len,0) < length else \\\n",
    "        int(round(length/row_len,0))\n",
    "    print('그래프가 {}X{}행렬로 그려집니다.'.format(row_len, col_len))\n",
    "    \n",
    "    # let's plot a histogram with the fitted parameters used by the function\n",
    "    fig = plt.figure(figsize=figsize_tuple)\n",
    "    for i in range(len(col)):\n",
    "        target = df_target[col[i]]\n",
    "        axi = fig.add_subplot(row_len,col_len,i+1)\n",
    "        sns.distplot(target , fit=norm, ax=axi)\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.legend([col[i]], loc=loc_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_vs_label(df_target_, label_str , col_target=None, figsize_tuple_ = (12,10), loc_='best'):\n",
    "    '''\n",
    "    df_target_의 col_target vs label를 행렬 그래프로 그리는 함수\n",
    "    df_target_ : 그래프들 그려볼 data frame\n",
    "    label_str : df_target_의 label을 str 형태로 입력.\n",
    "    col_target : label에 대한 분포를 파악하기를 원하는 features를 list형태로 입력.\n",
    "    figsize_tuple_ : 전체 그래프 사이즈를 튜플로 입력\n",
    "    loc_ : lengend 위치 설정\n",
    "      ex) loc_ = 'best', 'upper right', 'upper left', 'lower left', 'lower right', 'right', \n",
    "                'center left', 'center right', 'lower center', 'upper center', 'center' \n",
    "    '''\n",
    "    if col_target == None: #구분할 행을 입력하지 않으면 df의 전체 행을 입력해준다.\n",
    "        col = list(df_target_.columns)\n",
    "    else :\n",
    "        col = col_target    \n",
    "    \n",
    "    df_target = df_target_\n",
    "    figsize_tuple = figsize_tuple_\n",
    "    \n",
    "    \n",
    "    # data frame의 feature의 갯수에 따라 적절한 행과 열을 결정해준다.\n",
    "    length = len(col)\n",
    "    row_len = int(round(length**(1/2),0))\n",
    "    col_len = int(round(length/row_len,0))+1 if row_len*round(length/row_len,0) < length else \\\n",
    "        int(round(length/row_len,0))\n",
    "    print('그래프가 {}X{}행렬로 그려집니다.'.format(row_len, col_len))\n",
    "\n",
    "    # columns vs label\n",
    "    fig = plt.figure(figsize=figsize_tuple)\n",
    "    for i in range(len(col)):\n",
    "        axi = fig.add_subplot(row_len,col_len,i+1)\n",
    "        sns.regplot(x=col[i], y=label_str, data=df_target, ax=axi)\n",
    "        plt.legend([col[i]], loc=loc_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_feature_vs_freqency(df_target, col_name, loc_='best'):\n",
    "    '''\n",
    "    f_target의 feature인 col_name의 분포(frequency)를 행렬 그래프로 그리는 함수\n",
    "    df_target : 그래프를 그려볼 data frame\n",
    "    col_name : 그래프를 그려볼 featreu 이름 type = str\n",
    "    loc_ : lengend 위치 설정\n",
    "        ex) loc_ = 'best', 'upper right', 'upper left', 'lower left', 'lower right', 'right', \n",
    "            'center left', 'center right', 'lower center', 'upper center', 'center' \n",
    "    '''\n",
    "    from scipy.stats import norm, skew\n",
    "\n",
    "    target = df_target[col_name]\n",
    "    col_target = col_name\n",
    "    \n",
    "    # skewness 체크\n",
    "    print(\"Skewness: %f\" % target.skew())\n",
    "    \n",
    "    # let's plot a histogram with the fitted parameters used by the function\n",
    "    sns.distplot(target , fit=norm);\n",
    "    # get mean and standard deviation\n",
    "    (mu, sigma) = norm.fit(target)\n",
    "    # add legends to the plot\n",
    "    plt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n",
    "                loc=loc_)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(col_target);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_heatmap(df_corr, sort_by_col, column_list_=None, figsize_tuple=(12, 10), ascending_=False, palette_color='purple', fmt_=\".2f\"):\n",
    "    '''\n",
    "    df_corr의 feature+label 사이의 correlation coefficient를 heatmap으로 나타내는 함수.\n",
    "    df_corr : 상관계수 heatmap을 그려 볼 data frame\n",
    "    sort_by_col : 상관계수를 sort_by_col 기준으로 정렬 cf) 보통 label로 설정\n",
    "    fig_size (default=(12, 10)) : heatmap figure size\n",
    "    ascending_ (default=False) : 상관계수 내림차순 정렬(False), 오름차순 정렬(True)\n",
    "    palette_color (default='purple') : 상관계수 나타낼 색\n",
    "    fmt_ (default=\".2f\") : 표시되는 상관계수의 자릿수. cf) \".2f\": 소숫점 2자리수 float\n",
    "    '''\n",
    "    if column_list_ == None: #구분할 행을 입력하지 않으면 df의 전체 행을 입력해준다.\n",
    "        column_list = list(df_corr.columns)\n",
    "    else :\n",
    "        column_list = column_list_\n",
    "    \n",
    "    # 상관계수 구해서 그래프 그리기.\n",
    "    h_corr = df_corr[column_list].corr(method='pearson').sort_values(by=[sort_by_col], ascending = ascending_)\\\n",
    "                .sort_values(by=[sort_by_col], axis =1, ascending=ascending_)  \n",
    "    # 상관계수 dataframe /  가격과 상관계수 큰 순으로 정렬(행과 열 모두다 정렬)\n",
    "    \n",
    "    #heatmap으로 그리기\n",
    "    plt.figure(figsize=figsize_tuple)\n",
    "    sns.heatmap(h_corr, cmap=sns.light_palette(palette_color, as_cmap=True), annot=True, fmt=fmt_)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
