{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# starGAN 논문 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_image_label_data(sample_size, image_size, RGB=3):\n",
    "    '''\n",
    "    sample_size : 원하는 샘플 양 설정.\n",
    "    image_size :  원하는 이미지 사이즈 설정. ex) 128x128 -> image_size=128\n",
    "    RGB : default=3 \n",
    "    '''\n",
    "    N1 = sample_size\n",
    "    image_size_ = image_size\n",
    "    RGB_ = RGB\n",
    "    # np.random.normal : Draw random samples from a normal (Gaussian) distribution.\n",
    "    image_data = np.random.normal(size=[N1,image_size_,image_size_,RGB_]) \n",
    "    label_hair = tf.one_hot(np.random.randint(0,3,size=N1),depth=3)\n",
    "    label_gender = tf.one_hot(np.random.randint(0,2,size=N1),depth=1)\n",
    "    label_age = tf.one_hot(np.random.randint(0,2,size=N1),depth=1)\n",
    "    label_gender_age = np.append(label_gender,label_age, axis=1)\n",
    "    label = np.append(label_hair,label_gender_age, axis=1)\n",
    "    return (image_data, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 128, 128, 3)\n",
      "(2, 5)\n",
      "(2, 128, 128, 3)\n",
      "(2, 5)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 shape 파악\n",
    "# input이 들어가서 output으로 오류없이 나오는지만 확인._실제로 하면 GPU필요하고 하루 이상 돌아가야함.\n",
    "image_data, label = random_image_label_data(1000,128)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((image_data, label))\n",
    "train_dataset = train_dataset.batch(2) # 작은 배치로 해서 코드가 잘 돌아가는지 점검\n",
    "\n",
    "for images, labels in train_dataset.take(2): \n",
    "    print(images.shape)\n",
    "    print(labels.shape)\n",
    "    '''\n",
    "    (2, 128, 128, 3) #첫번째 2개씩 128,128,3짜리\n",
    "    (2, 5) # 첫번째 label 2개씩 불러오기\n",
    "    (2, 128, 128, 3)\n",
    "    (2, 5)\n",
    "    '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class 만들때, tf.keras.model ; 반드시 상속\n",
    "# Appendix에 나온 대로 하면됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Down sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- concat 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat(image, label):\n",
    "    '''\n",
    "    1차원 행렬인 label(array)을 다차원 행렬인 image(array)에 맞춰서 broadcasting해서 합쳐서 tensor로 출력해주는 함수.\n",
    "    label, image 는 array와 tensor형태 모두 허용.\n",
    "    '''\n",
    "    N = len(image) #  총 샘플 수\n",
    "    label_len =  len(label[0]) # 하나의 label의 list 길이 \n",
    "    image_size = len(image[0]) # 하나의 image의 한변의 길이\n",
    "\n",
    "    #비어있는 list 정의\n",
    "    concat = []\n",
    "    for i in range(N):\n",
    "        # label과 image i번째 성분\n",
    "        label_ = label[i]\n",
    "        image_ = image[i]\n",
    "        # 128x128x5짜리 성분이 1인 행렬 만들기\n",
    "        ones = np.ones((image_size, image_size, label_len))\n",
    "        # ones에서 [1,1,1,1,1]을 label_로 치환해서 128x128x5짜리 label 행렬 구축.\n",
    "        label_vol = np.where(ones==np.ones((label_len)), label_ , ones)\n",
    "        # image데이터와 label데이터를 concat해서 128x128x8행렬로 변경\n",
    "        image_label_concat = np.concatenate((image_, label_vol), axis=2)\n",
    "        # image_label_concat을 concat에 추가.\n",
    "        concat.append(image_label_concat)\n",
    "    # concat을 list에서 np.array로 바꾸고 출력.\n",
    "    concat_array = np.array(concat) \n",
    "    # list를 바로 텐서로 바꾸니 시간이 오래걸려서 array 바꾸고 tensor로 바꾸는 방식으로.\n",
    "    return tf.convert_to_tensor(concat_array, dtype=tf.float32) # tensor형태로 바꿔서 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "xxx = concat(image_data, label)\n",
    "#xxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Downsampling(tf.keras.Model):\n",
    "    def __int__(self):\n",
    "        super(Downsampling, self).__init__()\n",
    "        self.conv1 = Conv2D(64, kernel_size = 7, strides = 1, padding = 'SAME')\n",
    "        self.conv2 = Conv2D(128, kernel_size = 4, strides = 2, padding = 'SAME')\n",
    "        self.conv3 = Conv2D(256, kernel_size = 4, strides = 2, padding = 'SAME')\n",
    "        self.IN = InstanceNormalization() #구현필요\n",
    "        self.activation = layers.relu()\n",
    "    \n",
    "    def call(self, image, label):\n",
    "        x = concat(image,label) #구현필요\n",
    "        x = self.conv1(x)\n",
    "        x = self.IN(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.IN(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.IN(x)\n",
    "        x = self.activation(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=52, shape=(3,), dtype=float32, numpy=array([1., 5., 3.], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "cf) tf2.0에서 텐서 연산 예시\n",
    "'''\n",
    "tf.executing_eagerly()\n",
    "test = [[2.,-1.,4.]]\n",
    "sol = [[1.,4.,1.]]\n",
    "tf.norm(tf.math.subtract(test,sol),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=43, shape=(1, 3), dtype=float32, numpy=array([[ 1., -5.,  3.]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.subtract(test,sol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-18cef50bfaf5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m '''\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mgenerated_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_fake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#: fake image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0madv_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerated_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'generator' is not defined"
     ]
    }
   ],
   "source": [
    "'''\n",
    "loss 함수, D(c'|x) 이런거 어떻게 구현하지?\n",
    "'''\n",
    "\n",
    "generated_output = generator(concat(real_image, label_fake)) #: fake image\n",
    "\n",
    "def adv_loss(real_output, generated_output):\n",
    "    D_real = discriminator(real_output)  # real_output = real_image + cls 정답\n",
    "    D_fake = discriminator(generated_output) # generated_input = generated_image + cls 정답\n",
    "    return tf.reduce_mean(tf.log(D_real)+tf.log(1-D_fake))\n",
    "    \n",
    "def real_cls_loss(real_input): #?\n",
    "    D_real = discriminator(real_input) # real_input = real_image + cls 정답\n",
    "    return tf.reduce_mean(-tf.log(D_real))\n",
    "\n",
    "def fake_cls_loss(generated_output, label_fake): #cls 들어가야하는거 맞나?\n",
    "    D_fake = discriminator(label_fake, generated_output) # real_input = real_image + cls 정답\n",
    "    return tf.reduce_mean(-tf.log(D_fake))\n",
    "\n",
    "def rec_loss(real_output, generated_output, label_real):\n",
    "    G_real_from_fake = generator(conct(generated_output, label_real))\n",
    "    real_subt_G = tf.norm(tf.math.subtract(real_output,G_real_from_fake), axis=1 )#axis 수정??? \n",
    "    return tf.reduce_mean(real_subt_Rfake)\n",
    "\n",
    "def generator_loss(generated_output, lambda_cls, lambda_rec):\n",
    "    return adv_loss(real_output, generated_output) + lambda_cls*fake_cls_loss(generated_output, label_fake)\\\n",
    "        +lambda_rec*rec_loss(real_output, generated_output, label_real)\n",
    "\n",
    "def discriminator_loss(real_output, generated_output,  lambda_cls, real_input):\n",
    "    return -adv_loss(real_output, generated_output) + lambda_cls*real_cls_loss(real_input)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 128, 128, 8)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat = []\n",
    "image_size = 128\n",
    "label_len = 5\n",
    "i=0\n",
    "\n",
    "label_ = label.numpy()[i]\n",
    "image_ = image_data[i]\n",
    "ones = np.ones((image_size, image_size, label_len))\n",
    "label_vol = np.where(ones==np.ones((1,label_len)), label_ , ones)\n",
    "image_label_concat = np.concatenate((image_, label_vol), axis=2)\n",
    "concat.append(image_label_concat)\n",
    "np.array(concat).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 64, 64, 4)\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_dataset.take(1): \n",
    "    output = conv(images)\n",
    "    print(output.shape)\n",
    "#     print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(MyModel, self).__init__(name='my_model')\n",
    "        self.num_classes = num_classes\n",
    "        # Define your layers here.\n",
    "        self.dense_1 = layers.Dense(32, activation='relu')\n",
    "        self.dense_2 = layers.Dense(num_classes, activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Define your forward pass here,\n",
    "        # using layers you previously defined (in `__init__`).\n",
    "        x = self.dense_1(inputs)\n",
    "        return self.dense_2(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the loss functions and the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 논문에서 G와 D 각각 loss를 어떻게 구현하는지 파악해야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
